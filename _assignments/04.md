---
type: assignment
date: 2025-10-26
tag: 'Assignment #4'
title: 'Improving Training Efficiency'
pdf: https://cmu.box.com/s/qfbgf7pt2p571eo3jgap7hcukyv3hm4w
starter_code: https://cmu.box.com/s/sak23ysofurogo1citnmg3ib1vmh5zhm
submission_template: https://cmu.box.com/s/xycn269kq1hz14odbg2dfh54hwzzyyog
hide_from_announcments: false
due_event: 
    type: due
    date: 2025-11-06T23:59:59+3:30
    description: 'Assignment #4 due'
---

In this homework, you will explore strategies for making language models more efficient both in their training and inference phases. Large language models require significant computational resources due to their high memory consumption, large parameter counts, and the extensive compute needed for both training and serving. Efficiently training these models involves optimizing memory usage and using distributed training setups, which allow us to leverage multiple GPUs to process larger models or batches without running out of memory.